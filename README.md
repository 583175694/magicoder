# ðŸŽ© Magicoder: Source Code Is All You Need


<p align="left">
    <a href="https://arxiv.org/abs/1234.56789"><img src="https://img.shields.io/badge/arXiv-1234.56789-b31b1b.svg?style=for-the-badge">
    <a href="https://opensource.org/license/mit/"><img src="https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge">
    <a href="https://huggingface.co/ise-uiuc/"><img src="https://img.shields.io/badge/ðŸ¤—%20Hugging%20Face-ise--uiuc-%23ff8811.svg?style=for-the-badge">
</p>
<!-- <a href="https://huggingface.co/ise-uiuc"><img src="https://huggingface.co/datasets/huggingface/badges/resolve/main/follow-me-on-HF-xl.svg"></a> -->

<!--     <a href="https://hub.docker.com/r/universefly/repilot/tags"><img src="https://img.shields.io/badge/docker-universefly%2Frepilot-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white"></a> -->

<!-- [jw: add toc after the sections are ready] -->

<p align="left">
    ðŸŽ© <a href="#-magicoder-models">Magicoder Models</a>
    | ðŸ“‘ <a href="#-training-dataset">Training Dataset</a>
    | ðŸš€ <a href="#-quick-start">Quick Start</a>
</p>

> [!IMPORTANT]
> We are constantly working on improving the documentation and adding more implementation details. Please stay tuned!

## About

**Magicoder**s are powered by **OSS-Instruct**, a novel approach to enlightening LLMs with open-source code snippets to generate **low-bias** and **high-quality** instruction data for code. OSS-Instruct **mitigates the inherent bias** of the synthetic data generated by LLMs by empowering them with **a wealth of open-source references** for the production of more diverse, realistic, and controllable data.

<img width="2235" alt="magicoder-overview-png" src="assets/overview.png">


## ðŸŽ© Magicoder Models

|  Model  |  Checkpoint  | Size    | HumanEval (+) |   MBPP (+) | Demo | License |
| ----- |------| ---- |------|-------| ----- |  ----- | 
|  Magicoder-CL-7B  |   ðŸ¤— <a href="https://huggingface.co/ise-uiuc/Magicoder-CL-7B" target="_blank">HF Link</a>   |  7B  |  60.4 (55.5)   | 64.2 (52.6) | -- |  [Llama2](https://ai.meta.com/llama/license/)  |
|  Magicoder-*S*-CL-7B  |   ðŸ¤— <a href="https://huggingface.co/ise-uiuc/Magicoder-S-CL-7B" target="_blank">HF Link</a>   |  7B  |  70.7 (66.5)   | 68.4 (56.6) | -- |  [Llama2](https://ai.meta.com/llama/license/)  |
|  Magicoder-DS-6.7B  |   ðŸ¤— <a href="https://huggingface.co/ise-uiuc/Magicoder-DS-6.7B" target="_blank">HF Link</a>   |  6.7B  |  66.5 (60.4)   | 75.4 (61.9) | -- |  [DeepSeek](https://github.com/deepseek-ai/DeepSeek-Coder/blob/main/LICENSE-MODEL)  |
|  Magicoder-*S*-DS-6.7B  |   ðŸ¤— <a href="https://huggingface.co/ise-uiuc/Magicoder-S-DS-6.7B" target="_blank">HF Link</a>   |  6.7B  |  **76.8** (**70.7**)   | **75.7** (**64.4**) | -- |  [DeepSeek](https://github.com/deepseek-ai/DeepSeek-Coder/blob/main/LICENSE-MODEL)  |

## ðŸ“‘ Training Dataset

- [Magicoder-OSS-Instruct-75K](https://huggingface.co/datasets/ise-uiuc/Magicoder_oss_instruct_75k): generated through **OSS-Instruct** using `gpt-3.5-turbo-1106` and used to train both Magicoder and Magicoder-S series.
- [Magicoder-Evol-Instruct-110K](https://huggingface.co/datasets/ise-uiuc/Magicoder_evol_instruct_110k): decontaminated and redistributed from [theblackcat102/evol-codealpaca-v1](https://huggingface.co/datasets/theblackcat102/evol-codealpaca-v1), used to further finetune Magicoder series and obtain Magicoder-S models.


> [!NOTE]
> Magicoder models are trained on the synthetic data generated by `gpt-3.5-turbo-1106` developed by OpenAI. Please pay attention to OpenAI's [terms of use](https://openai.com/policies/terms-of-use) when using the models and the datasets.

## ðŸš€ Quick Start

<!-- [jw: inline the demo instead of redirecting it to a new link. put most things into code. add some concise desc.] -->

```bash
git clone https://github.com/ise-uiuc/magicoder.git
cd magicoder
pdm install
python magicoder_demo.py --base_model "ise-uiuc/Magicoder-S-DS-6.7B" \
                         --device "cuda:0" --port 8080
```

## Generating Synthetic Data with OSS-Instruct

Make sure you have set up your `OPENAI_API_KEY` and optionally `OPENAI_BASE_URL`. Then run with

```bash
python src/magicoder/generate_data.py \
  --seed_code_start_index ${START_INDEX_OF_RAW_DATA} \
  --max_new_data ${MAX_DATA_TO_GENERATE}
```

To continue an interrupted run, use `--continue_from` flag:

```bash
python src/magicoder/generate_data.py \
  --seed_code_start_index ${START_INDEX_OF_RAW_DATA} \
  --max_new_data ${MAX_DATA_TO_GENERATE} \
  --continue_from ${PATH_TO_DATA_FILE}
```

## Fine-tuning over OSS-Instruct Datasets

> To be documented soon!

## Citation

TODO
